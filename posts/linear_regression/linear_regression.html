<!DOCTYPE html>

<html class="no-js" lang="en-US">

<head>

	<meta charset="UTF-8">

	<meta name="viewport" content="width=device-width, initial-scale=1">

	<link rel="Shortcut Icon" href="../../assets/icon.png" type="image/x-icon">

	<title>Linear Regression | Walker's ML Blog</title>

	<style type="text/css">
		img.wp-smiley,
		img.emoji {
			display: inline !important;
			border: none !important;
			box-shadow: none !important;
			height: 1em !important;
			width: 1em !important;
			margin: 0 .07em !important;
			vertical-align: -0.1em !important;
			background: none !important;
			padding: 0 !important;
		}
	</style>

	<link rel='stylesheet' id='swell-style-css'  href='../../CSS/style.css' type='text/css' media='all' />

	<link rel='stylesheet' id='swell-style-mobile-css'  href='../../CSS/style-mobile.css' type='text/css' media='all' />

	<script type='text/javascript' src='../../CSS/jquery.js'></script>

	<script type='text/javascript' src='../../CSS/superfish.js'></script>

	<meta name="generator" content="WordPress 4.6.1" />

	<link rel='dns-prefetch' href='//v0.wordpress.com'>
	<style type='text/css'>img#wpstats{display:none}</style>		<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>
	<link rel="stylesheet" href="styles.css">

	<script type="text/x-mathjax-config">
	  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script type="text/javascript"
	  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
</head>

<body class="home blog infinite-scroll">

	<!-- BEGIN #wrapper -->
	<div id="wrapper">
		<div class="container">
			<div id="header">
				<div id="custom-header"  style="background-image: url(../../assets/wallpaper.jpg);">
					<h1 id="logo" class="vertical-center text-center">
						<a>
							<img src="../../assets/title.png" alt="" />
							<span class="logo-text"></span>
						</a>
					</h1>
					<img class="hide-img" src="../../assets/wallpaper.jpg" height="480" width="1800" alt="Premium Swell Theme Demo" />
				</div>
			</div>


			<!-- BEGIN #navigation -->
			<nav id="navigation" class="navigation-main clearfix" role="navigation">
				<button class="menu-toggle"><i class="fa fa-bars"></i></button>
				<div class="menu-main-menu-container"><ul id="menu-main-menu" class="menu"><li id="menu-item-35" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-35"><a href="../../index.html">Home</a></li>

				<li id="menu-item-161" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-161"><a href="index.html">Blog</a>
					<ul class="sub-menu">
						<li id="menu-item-168" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-168"><a href="index.html">Machine Learning</a></li>
					</ul>
				</li>
				<li id="menu-item-90" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-90"><a href="https://Contact">Contact</a></li>
				</ul></div>
			</nav>

			<div class="post-245 post type-post status-publish format-standard has-post-thumbnail hentry category-blog category-work tag-free tag-ocean tag-theme tag-wordpress" id="page-245">
				<div class="row">
					<div class="content">
						<div class="columns eleven" style="width:100%">
							<div id="infinite-container" class="postarea">

								<!-- Post -->
								<div class="blog-holder shadow radius-full post-245 post type-post status-publish format-standard has-post-thumbnail hentry category-blog category-work tag-free tag-ocean tag-theme tag-wordpress" id="post-245">

									<div class="article">
										<div class="entry">
											<div class="post-date">
												<p><i class="fa fa-clock-o"></i> <span class="meta-prep meta-prep-author">Posted:</span> <a title="9:47 pm" rel="bookmark"><span class="entry-date">March 10, 2017</span></a></p>
											</div>
											<h2 class="headline"><a rel="bookmark" title="A WordPress Theme Crafted With The Force Of The Ocean">Linear Regression</a></h2>
											<span class="divider-small"></span>
										</div>
										<h4>What Is Linear Regression?</h4>
										<p>You might've come across the term 'line of best fit' at school if you took an introductory statistics course, which is a line on a scatter plot that best represents the data. In the case of a two dimensional plot, this line will be $y=mx+b$.</p>
										<a class="feature-img radius-top" rel="bookmark" title="Permalink to A WordPress Theme Crafted With The Force Of The Ocean"><img width="1800" height="288" src="https://ajunwalker.github.io/assets/wallpaper.jpg" style="height:288px; width:432px" class="attachment-swell-featured-large size-swell-featured-large wp-post-image" alt="post-17" srcset="https://ajunwalker.github.io/posts/linear_regression/house_fit.png" sizes="(max-width: 1800px) 100vw, 432px" /></a>
										<p>The idea behind linear regression in machine learning is to find the 'line of best fit' using the power of mathematics and the processing power of computers to perform a guided trial-and-error to approximate a line that best represents the data.</p>
										<h4>Predict The Price Of Your House</h4>
										<p>Suppose you are trying to sell your house and you are given a list of other houses on sale. A typical posting may contain attributes such as size in squared meters, number of bedrooms, and number of carparks, but you can't seem to find a house with similar attributes. The question you might want to ask is, "How can I use the postings list to infer an appropriate price for my house?" Luckily, this problem can be solved used linear regression.</p>
										<p>For sake of argument, let's only use the size of the houses to infer the price of your house. Below is a list of house sizes and their corresponding house prices around your area.</p>
										$$
										\begin{array}{c|c|c}
										n & \text{Size ($m^{2}$)} & \text{Price} \\
										\hline
										1 & 641 & 460 \\
										2 & 432 & 232 \\
										3 & 467 & 315 \\
										4 & 259 & 178
										\end{array}
										$$
										<p>If we plot the data on a scatter plot, we will get a graph like this:</p>
										<a class="feature-img radius-top" rel="bookmark" title="Permalink to A WordPress Theme Crafted With The Force Of The Ocean"><img width="1800" height="288" src="https://ajunwalker.github.io/assets/wallpaper.jpg" style="height:288px; width:432px" class="attachment-swell-featured-large size-swell-featured-large wp-post-image" alt="post-17" srcset="https://ajunwalker.github.io/posts/linear_regression/house_scatter.png" sizes="(max-width: 1800px) 100vw, 432px" /></a>
										<pre>
											1| # Initializing the data in Python <br>
											2| size = [641.0, 432.0, 467.0, 259.0] <br>
											3| price = [460.0, 232.0, 315.0, 178.0]
										</pre>
										<h4>Initialization</h4>
										<p>So now the question is, "How can we perform linear regression on the data to fit a line?" In order to perform linear regression, we first need to start with a random equation of a line in the form of:</p>
										$$ f(x) = \theta_{0}x_{0} + \theta_{1}x_{1}, $$
										<p>where $\theta_{0}$ and $\theta_{1}$ are the two coefficients of the line, namely the y intercept and the slope, $x_{0}$ is always 1 and $x_{1}$ is the size of the house. Furthermore, the coefficients should be randomly chosen between -0.5 and 0.5. There is a good explanation as to why it should be between this range, but as it is beyond the scope of this tutorial, let's just say it's good practice.</p>
										<p>The following is an arbitrarily created equation we will be using for the rest of this tutorial:</p>
										$$ f(x) = -0.25x_{0} + 0.25x_{1} $$
										<pre>
											4| # Initializing the function coefficients <br>
											5| coefficient = [-0.25, 0.25] <br>
										</pre>
										<h4>Mean Squared Error</h4>
										<p>The general approach in linear regression is to start with a randomized equation of a line, and slowly 'tweak' the coefficients of the equation to get as close as possible to the correct position. Before we can even attempt to tweak the coefficients, we need to figure out how off our randomized line is. We can do this by calculating how far each point is from the line, a.k.a. calculating the mean squared error (MSE). The formula for MSE is the following:</p>
										$$ J(\theta_{0},\theta_{1}) = {{1 \over n} \sum^{n}_{i=1}{(f(x)-y)^{2}}}.$$
										<p>Here $f(x)$ refers to the equation of the line we created earlier, y refers to the actual value we are trying to predict, and n is the number of data points we have. If we replace these variables with values we are concerned with for predicting house prices, we will get the following:</p>
										$$ J(\theta_{0},\theta_{1}) = \small \frac{(160 - 460)^{2} + (107.75 - 232)^{2} + (116.5 - 315)^{2} + (64.5 - 178)^{2}}{4} = 39430.64. $$
										<p>According to MSE, we have an error of 39430.64, which is a pretty large error. This is because the the size of the houses are quite large relative to the coefficients of the function and we must normalize them so we start with a smaller error and it does not take forever to find the line of best fit. The method we are going to use to normalize the size of the houses is</p>
										$$ x' = \frac{x-\bar{x}}{max(x)-min(x)},$$
										<p>where $x$ is the original value of the size, $\bar{x}$, $max$ and $min$ are the mean, maximum and minimum of the size of houses respectively. Keep in mind that as the points are not lined up properly, it is impossible for us to get an error of zero. This turns out to be the case in most scenarios when we are dealing with real world problems.</p>
										<pre>
											<a class="code_unlink" style="padding-left:8px"></a> 6| # Normalize values</a> <br>
											<a class="code_unlink" style="padding-left:8px"> 7| def normalize(x): <br>
											<a class="code_unlink" style="padding-left:8px"></a> 8| <a class="code_unlink" style="padding-left:30px">mean = sum(x)/float(len(x))</a> <br>
											<a class="code_unlink" style="padding-left:8px"></a> 9| <a class="code_unlink" style="padding-left:30px">minimum = min(x)</a> <br>
											10| <a class="code_unlink" style="padding-left:30px">maximum = max(x)</a> <br>
											11| <a class="code_unlink" style="padding-left:30px">return [(i-mean)/(maximum-minimum) for i in x]</a> <br>
										</pre>
										<h4>The Derivative</h4>
										<p>Now that we have calculated the error, we want to decrease the error as much as we can using derivatives. If you are unfamiliar with derivatives, I strongly encourage you to watch a great series on derivates <a href="https://www.khanacademy.org/math/differential-equations">here</a>.</p>
										<p>So how can we minimize the error produced by the MSE formula? One way to approach this problem is to calculate the derivative of the MSE function - which we will call the $error$ $function$ from this point on, using the chain rule and equate it to zero. I have already found the derivative for you below:</p>
										$$ \frac{d}{d \theta_{j}}(J(\theta_{0},\theta_{1}) = \frac{d}{d \theta_{j}}\left({1 \over n}  \sum^{n}_{i=1}{(f(x)-y)^{2}}\right) = {2 \over n} \sum^{n}_{i=1}{(f(x)-y)x_{j}}.$$
										<pre>
											12| # Compute the MSE and its derivative</a> <br>
											13| def mse(x, y, deriv=False): <br>
											14| <a class="code_unlink" style="padding-left:30px">error = []</a> <br>
											15| <a class="code_unlink" style="padding-left:30px">for data, target in zip(x,y):</a> <br>
											16| <a class="code_unlink" style="padding-left:60px">if deriv == True:</a> <br>
											16| <a class="code_unlink" style="padding-left:90px">error.append(2*((coefficient[0] + coefficient[1]*data)-target)/len(x))</a> <br>
											17| <a class="code_unlink" style="padding-left:60px">else:</a> <br>
											18| <a class="code_unlink" style="padding-left:90px">error.append((((coefficient[0] + coefficient[1]*data)-target)**2)/len(x))</a> <br>
											19| <a class="code_unlink" style="padding-left:30px">return error</a>
										</pre>
										<h4>Gradient Descent</h4>
										<p>At this point, we have learnt all the tools we need to fit a line of best fit to our data. Our next step is use a method called Gradient Descent which uses the gradient of the error function to move our error to the minimum of the error function. The formula for gradient descent is the following:</p>
										$$ \theta_{j} := \theta_{j} - a \frac{d}{d\theta_{j}}J(\theta_{0},\theta_{1}).$$
										<p>where $\theta_{j}$ is the $j_{th}$ coefficient of our equation, $a$ is the learning rate which is a constant that should be smaller than 1, and $\frac{d}{d\theta_{j}}(J(\theta_{0},\theta_{1}))$ is the derivative of the error function with respect to the $j_{th}$ coefficient. The function may look daunting at first, but all it is doing is slightly changing the coefficients of our current line equation in the opposite direction of gradient which is controlled by learning rate. The learning rate is very important here because it determines the size of the step you take in the direction. This means if the learning rate is too large, the algorithm may overshoot the minimum and attempt to go backwards, but will keep overshooting as the steps are too large. To get a better understanding of how the learning rate affects the algorithm, I strongly encourage you to experiment with different rates between 1 and 0.00001.</p>
										<p>Before we move on, the concept of $epochs$ must be discussed. The update method that we have arrived at only minimizes the error by a very small amount. In order for the error to be minimized as much as much possible, we must repeat the update process several times. In machine learning, there is a special term called $epochs$, which refers to the number of times an update is performed. For this example, we will choose 1000, but feel free to experiment with smaller and larger values to see how it affects our line.</p>
										<pre>
											20| # Calculate the error of our line</a> <br>
											21| def test(x, y):
											22| <a class="code_unlink" style="padding-left:30px">error = sum(mse(x, y))</a> <br>
											23| <a class="code_unlink" style="padding-left:30px">return error</a> <br>
											24| <br>
											25| # Perform gradient descent</a> <br>
											26| def gradient_descent(x, y, epoch=1000): <br>
											27| <a class="code_unlink" style="padding-left:30px">lr = 0.01 # Learning rate</a> <br>
											28| <a class="code_unlink" style="padding-left:30px">for i in range(epoch):</a> <br>
											29| <a class="code_unlink" style="padding-left:60px">error_theta_0 = mse(x, y, deriv=True)</a> <br>
											30| <a class="code_unlink" style="padding-left:60px">error_theta_1 = [error_theta_0[i] * x[i] for i in range(len(x))]</a> <br>
											31| <a class="code_unlink" style="padding-left:60px">coefficient[0] -= lr*sum(error_theta_0) </a> <br>
											32| <a class="code_unlink" style="padding-left:60px">coefficient[1] -= lr*sum(error_theta_1) </a> <br>
											33| <a class="code_unlink" style="padding-left:60px">if i % 100 == 0:</a> <br>
											34| <a class="code_unlink" style="padding-left:90px">print("Error at "+ str(i) +" epochs: " + str(test(x,y)))</a> <br>
										</pre>
										<h4>Putting it all together</h4>
										<p>Now that we've learnt and coded everything we need to find the line of best fit, we can run the code to test how we have done!</p>
										<pre>
											35| size_norm = normalize(size) <br>
											36| gradient_descent(size_norm, price) <br>
										</pre>
										<a class="feature-img radius-top" rel="bookmark" title="Permalink to A WordPress Theme Crafted With The Force Of The Ocean"><img width="1800" height="288" src="https://assets/wallpaper.jpg" style="height:288px; width:432px" class="attachment-swell-featured-large size-swell-featured-large wp-post-image" alt="post-17" srcset="https://ajunwalker.github.io/posts/linear_regression/epochs.gif" sizes="(max-width: 1800px) 100vw, 432px" /></a>
										<p>If you got the following output, then we've successfully implemented linear regression!</p>
										<pre>
											Error at 0 epochs: 95679.70737917697 <br>
											Error at 100 epochs: 8637.12391268404 <br>
											Error at 200 epochs: 4705.53249958228 <br>
											Error at 300 epochs: 3187.3153746545486 <br>
											Error at 400 epochs: 2285.94844902192 <br>
											Error at 500 epochs: 1742.1435634950478 <br>
											Error at 600 epochs: 1413.9050135486725 <br>
											Error at 700 epochs: 1215.7787540052796 <br>
											Error at 800 epochs: 1096.1888080267715 <br>
											Error at 900 epochs: 1024.003750987116
										</pre>
									</div>
								</div>
								<!-- End Post -->

							</div>
						</div>

					</div>
				</div>
			</div>
		</div>

		<!-- Footer -->
		<div class="footer">
			<div class="row">
				<div class="footer-information">
					<div>
						<div>
							<p style="text-align:center;font-size:70%;">Copyright &copy; 2016 &middot; All Rights Reserved &middot; Andrew Walker</p>
						</div>
					</div>
				</div>
			</div>
		</div>
	</div>

</body>
</html>
